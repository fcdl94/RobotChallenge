{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import training\n",
    "import OBC.networks\n",
    "import data_loader as dl\n",
    "import Piggyback.networks as pbnet\n",
    "import Rebuffi.networks as rbnet\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import copy\n",
    "\n",
    "from OBC.ClassificationMetric import ClassificationMetric\n",
    "from Piggyback.networks import *\n",
    "from Piggyback.custom_layers import *\n",
    "from Rebuffi.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/fcdl/Develop/Data/sample'\n",
    "batch = 4\n",
    "rgb = True\n",
    "depth = False\n",
    "\n",
    "from Depth.NYUDataset import NYUDataset\n",
    "cost_function = nn.CrossEntropyLoss()\n",
    "metric = ClassificationMetric()\n",
    "# Image folder for train and val\n",
    "train_loader = dl.get_image_folder_loaders(folder + \"/train\", NYUDataset, \"SM\", batch, rgb, depth)\n",
    "test_loader = dl.get_image_folder_loaders(folder + \"/val\", NYUDataset, \"NO\", batch, rgb, depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pretrained loaded\n",
      "conv1.mask.0 requires_grad: True\n",
      "bn1.0.weight requires_grad: True\n",
      "bn1.0.bias requires_grad: True\n",
      "layer1.0.conv1.mask.0 requires_grad: True\n",
      "layer1.0.bn1.0.weight requires_grad: True\n",
      "layer1.0.bn1.0.bias requires_grad: True\n",
      "layer1.0.conv2.mask.0 requires_grad: True\n",
      "layer1.0.bn2.0.weight requires_grad: True\n",
      "layer1.0.bn2.0.bias requires_grad: True\n",
      "layer1.1.conv1.mask.0 requires_grad: True\n",
      "layer1.1.bn1.0.weight requires_grad: True\n",
      "layer1.1.bn1.0.bias requires_grad: True\n",
      "layer1.1.conv2.mask.0 requires_grad: True\n",
      "layer1.1.bn2.0.weight requires_grad: True\n",
      "layer1.1.bn2.0.bias requires_grad: True\n",
      "layer2.0.conv1.mask.0 requires_grad: True\n",
      "layer2.0.bn1.0.weight requires_grad: True\n",
      "layer2.0.bn1.0.bias requires_grad: True\n",
      "layer2.0.conv2.mask.0 requires_grad: True\n",
      "layer2.0.bn2.0.weight requires_grad: True\n",
      "layer2.0.bn2.0.bias requires_grad: True\n",
      "layer2.0.downsample.0.mask.0 requires_grad: True\n",
      "layer2.0.bn3.0.weight requires_grad: True\n",
      "layer2.0.bn3.0.bias requires_grad: True\n",
      "layer2.1.conv1.mask.0 requires_grad: True\n",
      "layer2.1.bn1.0.weight requires_grad: True\n",
      "layer2.1.bn1.0.bias requires_grad: True\n",
      "layer2.1.conv2.mask.0 requires_grad: True\n",
      "layer2.1.bn2.0.weight requires_grad: True\n",
      "layer2.1.bn2.0.bias requires_grad: True\n",
      "layer3.0.conv1.mask.0 requires_grad: True\n",
      "layer3.0.bn1.0.weight requires_grad: True\n",
      "layer3.0.bn1.0.bias requires_grad: True\n",
      "layer3.0.conv2.mask.0 requires_grad: True\n",
      "layer3.0.bn2.0.weight requires_grad: True\n",
      "layer3.0.bn2.0.bias requires_grad: True\n",
      "layer3.0.downsample.0.mask.0 requires_grad: True\n",
      "layer3.0.bn3.0.weight requires_grad: True\n",
      "layer3.0.bn3.0.bias requires_grad: True\n",
      "layer3.1.conv1.mask.0 requires_grad: True\n",
      "layer3.1.bn1.0.weight requires_grad: True\n",
      "layer3.1.bn1.0.bias requires_grad: True\n",
      "layer3.1.conv2.mask.0 requires_grad: True\n",
      "layer3.1.bn2.0.weight requires_grad: True\n",
      "layer3.1.bn2.0.bias requires_grad: True\n",
      "layer4.0.conv1.mask.0 requires_grad: True\n",
      "layer4.0.bn1.0.weight requires_grad: True\n",
      "layer4.0.bn1.0.bias requires_grad: True\n",
      "layer4.0.conv2.mask.0 requires_grad: True\n",
      "layer4.0.bn2.0.weight requires_grad: True\n",
      "layer4.0.bn2.0.bias requires_grad: True\n",
      "layer4.0.downsample.0.mask.0 requires_grad: True\n",
      "layer4.0.bn3.0.weight requires_grad: True\n",
      "layer4.0.bn3.0.bias requires_grad: True\n",
      "layer4.1.conv1.mask.0 requires_grad: True\n",
      "layer4.1.bn1.0.weight requires_grad: True\n",
      "layer4.1.bn1.0.bias requires_grad: True\n",
      "layer4.1.conv2.mask.0 requires_grad: True\n",
      "layer4.1.bn2.0.weight requires_grad: True\n",
      "layer4.1.bn2.0.bias requires_grad: True\n",
      "fc.0.weight requires_grad: True\n",
      "fc.0.bias requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"p\" # \"p\" or \"q\" or \"rs\" or \"rp\"\n",
    "# Initialize the specified architecture.\n",
    "if MODEL == 'p':\n",
    "    model = pbnet.piggyback_net18([10,1,10], True)\n",
    "elif MODEL == 'q':\n",
    "    model = pbnet.quantized_net18([10,1,10], True)\n",
    "elif MODEL == 'rs':\n",
    "    model = rbnet.rebuffi_net18([10,1,10], serie=True, pre_imagenet=True)\n",
    "elif MODEL == 'ps':\n",
    "    model = rbnet.rebuffi_net18([10,1,10], serie=False, pre_imagenet=True)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "model.set_index(0)\n",
    "\n",
    "# Consider this as a sanity check\n",
    "for name, par in model.named_parameters():\n",
    "    if par.requires_grad:\n",
    "        print(name + \" requires_grad: \" + str(par.requires_grad))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time of Epoch 1: 15:36:44.973915\n",
      "Train Epoch: 1 [   0/  50 ( 0%)]\tAvgLoss: 1.079536\n",
      "Train Epoch: 1 [  40/  50 (77%)]\tAvgLoss: 2.385605\n"
     ]
    }
   ],
   "source": [
    "from Piggyback.multiple_optim import MultipleOptimizer \n",
    "\n",
    "lr = 0.005\n",
    "adamlr = 0.0001\n",
    "decay = 0.00005\n",
    "step = 10\n",
    "epoch = 1\n",
    "momentum = 0.9\n",
    "\n",
    "exp = copy.deepcopy(model.state_dict())\n",
    "\n",
    "model.bn1[2].weight.requires_grad = True # intended error to check if it works.\n",
    "\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = list(filter(lambda p: (id(p) not in ignored_params) and p.requires_grad, model.parameters()))\n",
    "fc_params = list(filter(lambda p: p.requires_grad, model.fc.parameters()))\n",
    "# set optimizer\n",
    "optimizer_a = optim.Adam(base_params, lr=adamlr, weight_decay=decay)\n",
    "optimizer_b = optim.SGD(fc_params, lr=lr, momentum=momentum, weight_decay=decay)\n",
    "scheduler_a = optim.lr_scheduler.StepLR(optimizer_a, step)\n",
    "scheduler_b = optim.lr_scheduler.StepLR(optimizer_b, step)\n",
    "scheduler = MultipleOptimizer(scheduler_a, scheduler_b)\n",
    "optimizer = MultipleOptimizer(optimizer_a, optimizer_b)\n",
    "\n",
    "## Consider this as a sanity check\n",
    "#for name, par in model.named_parameters():\n",
    "#    if par.requires_grad:\n",
    "#        print(name + \" requires_grad: \" + str(par.requires_grad))\n",
    "\n",
    "# NOTE: loss function is a parameter as well as the metric function\n",
    "loss_epoch = training.train_epoch(model, 1, train_loader, optimizer, cost_function)\n",
    "result = training.test_epoch(model, test_loader, cost_function, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1.2.weight isn't changed while it should\n"
     ]
    }
   ],
   "source": [
    "par = model.state_dict()\n",
    "for name, par in model.named_parameters():\n",
    "    if not torch.equal(exp[name], par):\n",
    "        if not par.requires_grad:\n",
    "            print(name + \" is changed while it shouldn't\")\n",
    "    else:\n",
    "        if par.requires_grad:\n",
    "            print(name + \" isn't changed while it should\")\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, BasicMaskedBlock) \\\n",
    "    or isinstance(m, QuantizedConv2d) \\\n",
    "    or isinstance(m, MaskedConv2d) \\\n",
    "    or isinstance(m, MaskedNet) \\\n",
    "    or isinstance(m, BasicRebuffiBlock):\n",
    "        if m.index != 0:\n",
    "            print(m.__class__)\n",
    "\n",
    "    if isinstance(m, SerieAdapterModule) \\\n",
    "    or isinstance(m, ParallelAdapterModule) \\\n",
    "    or isinstance(m, RebuffiNet):\n",
    "        if m.task != 0:\n",
    "            print(m.__class__)\n",
    "\n",
    "            \n",
    "# output should be:\n",
    "# bn1.2.weight isn't changed while it should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-03 *\n",
      "       [[10.0000, 10.0000, 10.0000],\n",
      "        [10.0000, 10.0000, 10.0000],\n",
      "        [10.0000, 10.0000, 10.0000]])\n",
      "tensor([[ 0.0576, -0.0951, -0.0203],\n",
      "        [-0.0746, -0.7993, -0.2128],\n",
      "        [ 0.0656, -0.0965, -0.0121]])\n",
      "tensor([ 0.3090,  0.2147,  0.2366,  0.4259,  0.5137,  0.2181,  0.2204,\n",
      "         0.2300,  0.2640,  0.2695,  0.2138,  0.4602,  0.2661,  0.2319,\n",
      "         0.3900,  0.2389,  0.2660,  0.3634,  0.3474,  0.2477])\n",
      "tensor(1.00000e-02 *\n",
      "       [ 0.8571,  3.8492, -3.9927, -0.8347,  2.5711, -3.5917, -3.2478,\n",
      "         2.8026,  0.1955, -2.8098, -0.2178, -2.3266, -2.7773,  2.0527,\n",
      "        -4.3766,  1.8779, -4.0299, -0.0310,  4.0682, -0.9134])\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1[0].conv1.mask[0][0][0])\n",
    "print(model.layer1[0].conv1.weight[0][0])\n",
    "print(model.layer1[0].bn1[0].weight[0:20])\n",
    "print(model.fc[2].weight[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [[ 0.9644,  1.0279,  1.0580],\n",
      "        [ 0.9530,  0.8965,  0.9614],\n",
      "        [ 1.1038,  0.8864,  0.8833]])\n",
      "tensor([[ 0.0576, -0.0951, -0.0203],\n",
      "        [-0.0746, -0.7993, -0.2128],\n",
      "        [ 0.0656, -0.0965, -0.0121]])\n",
      "tensor([ 0.3093,  0.2147,  0.2373,  0.4256,  0.5130,  0.2183,  0.2212,\n",
      "         0.2305,  0.2637,  0.2704,  0.2148,  0.4612,  0.2664,  0.2314,\n",
      "         0.3890,  0.2389,  0.2667,  0.3631,  0.3464,  0.2474])\n",
      "tensor(1.00000e-02 *\n",
      "       [ 0.8571,  3.8492, -3.9927, -0.8347,  2.5711, -3.5917, -3.2478,\n",
      "         2.8026,  0.1955, -2.8098, -0.2178, -2.3266, -2.7773,  2.0527,\n",
      "        -4.3766,  1.8779, -4.0299, -0.0310,  4.0682, -0.9134])\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1[0].conv1.mask[0][0][0])\n",
    "print(model.layer1[0].conv1.weight[0][0])\n",
    "print(model.layer1[0].bn1[0].weight[0:20])\n",
    "print(model.fc[2].weight[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
